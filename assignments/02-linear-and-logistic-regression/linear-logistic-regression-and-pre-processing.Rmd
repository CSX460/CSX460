---
title: "week4 assignments"
author: "Christopher Brown"
date: "September 30, 2015"
output: html_document
---

# Readings

In **Applied Predictive Modeling** (APM), Read:
- Chapter 4 - Overfitting and Model Tuning
- Chapter 5 - Regression Models
- Chapter 6 , esp. 6.2 - Linear Regression
- Chapter 12.2 - Logistic Regression 

- [A Short Introduction to the Caret Package](https://cran.r-project.org/web/packages/caret/vignettes/caret.pdf). Make sure that you work along with the text.   
  


# Problem Set 

DUE: *In Class Monday October 12th*

The assigments are designed to be completed using [RMarkdown](http://rmarkdown.rstudio.com/). 

> R Markdown is an authoring format that enables easy creation of dynamic 
> documents, presentations, and reports from R. It combines the core syntax of
> markdown (an easy-to-write plain text format) with embedded R code chunks that
> are run so their output can be included in the final document. R Markdown
> documents are fully reproducible (they can be automatically regenerated 
> whenever underlying R code or data changes).


For questions requiring: 

- textual answers: record your answer in plain text
- code: place the code in the RMarkdown code fence. 

Show all code used to arrive at the answers.


## Finish in-class assignments


## ***APM*** 6.2 (a)-(d)

```{r}
# Place your code here
library(AppliedPredictiveModeling)
data(permeability)
```

(a) No response required.

(b)   

```{r}
# place R code here
library(caret)
ncol(fingerprints)
nzv_cols = nearZeroVar(fingerprints)
if(length(nzv_cols) > 0) {
    fingerprints <- fingerprints[, -nzv_cols]
}
ncol(fingerprints)
```

(c)
```{r}
# place R code here
library(caTools)
set.seed(123456)
split = sample.split(permeability, SplitRatio = 0.7)
train = subset(fingerprints, split==TRUE)
test = subset(fingerprints, split==FALSE)
perm_train = subset(permeability, split==TRUE)
perm_test = subset(permeability, split==FALSE)

# library(pls)
# pls1 = mvr(perm_train ~ train)
# summary(pls1)
# plot(pls1)
set.seed(123456)
pls = train(x = train, y = perm_train, method = "pls", tuneGrid = expand.grid(ncomp = 1:10), trControl = trainControl(method = "LGOCV"))
ncomp = 1:10
plot(pls)
plot(ncomp, pls$results$Rsquared)
min(pls$results$Rsquared)
```

(d) 
```{r}
# place R code here
pred = predict(pls, newdata=test)
plot(perm_test, pred)
```



## German Credit Data ## 

The University of California, Irvine [Machine Learning Repository](https://archive.ics.uci.edu/ml/index.html). One popular data set is the [German Credit Data](https://archive.ics.uci.edu/ml/datasets/Statlog+%28German+Credit+Data). Using this data, create a logistic regression model. 

```{r warning=FALSE}
data(GermanCredit)
set.seed(123456)
split = sample.split(GermanCredit$Class, SplitRatio = 0.7)
train = subset(GermanCredit, split==TRUE)
test = subset(GermanCredit, split==FALSE)

# Reference: APM pp. 85 - 87
svmFit = train(Class ~ ., data = train, method = "svmRadial", preProc = c("center", "scale"), tuneLength = 10, trControl = trainControl(method = "repeatedcv", repeats = 5))
plot(svmFit, scales = list(x = list(log = 2)))
svmFit

pred = predict(svmFit, test)
plot(test$Class, pred)
````

