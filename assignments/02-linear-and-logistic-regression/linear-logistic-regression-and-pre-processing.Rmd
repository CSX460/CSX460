---
title: "week4 assignments"
author: "Christopher Brown"
date: "September 30, 2015"
output: html_document
---

# Readings

In **Applied Predictive Modeling** (APM), Read:
- Chapter 4 - Overfitting and Model Tuning
- Chapter 5 - Regression Models
- Chapter 6 , esp. 6.2 - Linear Regression
- Chapter 12.2 - Logistic Regression 

- [A Short Introduction to the Caret Package](https://cran.r-project.org/web/packages/caret/vignettes/caret.pdf). Make sure that you work along with the text.   
  


# Problem Set 

DUE: *In Class Monday October 12th*

The assigments are designed to be completed using [RMarkdown](http://rmarkdown.rstudio.com/). 

> R Markdown is an authoring format that enables easy creation of dynamic 
> documents, presentations, and reports from R. It combines the core syntax of
> markdown (an easy-to-write plain text format) with embedded R code chunks that
> are run so their output can be included in the final document. R Markdown
> documents are fully reproducible (they can be automatically regenerated 
> whenever underlying R code or data changes).


For questions requiring: 

- textual answers: record your answer in plain text
- code: place the code in the RMarkdown code fence. 

Show all code used to arrive at the answers.


## Finish in-class assignments


## ***APM*** 6.2 (a)-(d)

```{r}
# Place your code here
library(caret)
library(AppliedPredictiveModeling)
library(ggplot2)
data(permeability)
```

(a) No response required.

(b)   

```{r}
#plot the percent of total permeability
plot(x=permeability , y = permeability/nrow(permeability))

#Identify and remove near zero predictors
nearzero_Fingerprints <- nearZeroVar(fingerprints)
nonnearzero_Fingerprints <- fingerprints[,-nearzero_Fingerprints]


```

(c)
```{r}
#Split data into training and test sets
set.seed(200)
trainingRows <- createDataPartition(permeability,p = 0.75,list = FALSE)

trainFingerprints <- nonnearzero_Fingerprints[trainingRows,]
trainPermeability <- permeability[trainingRows,]

testFingerprints <- nonnearzero_Fingerprints[-trainingRows,]
testPermeability <- permeability[-trainingRows,]

#model training
set.seed(200)
ctrl <- trainControl(method = "LGOCV")

plsTune <- train(x = trainFingerprints, y = log10(trainPermeability),method = "pls",tuneGrid = expand.grid(ncomp = 1:15),trControl = ctrl)
```

(d) 
```{r}
figer_predict <- predict( plsTune,type='response')
```



## German Credit Data ## 

The University of California, Irvine [Machine Learning Repository](https://archive.ics.uci.edu/ml/index.html). One popular data set is the [German Credit Data](https://archive.ics.uci.edu/ml/datasets/Statlog+%28German+Credit+Data). Using this data, create a logistic regression model. 

```{r}
library(ROCR)
German <- read.csv(file.choose())

#transform data
German$Creditability <- (German$Creditability - 1) %>% as.logical

fit.1<-glm(Creditability~.,data=German,family="binomial")
summary(fit.1)

fit.2<- glm(Creditability~.-Purpose -Age..years. -o.of.Credits.at.this.Bank 
            -Occupation -No.of.dependents -Telephone -Guarantors
           ,family="binomial")
summary(fit.2)

#Calculate RMSE
rmse(fit.1$fitted.values, German$Creditability)
rmse(fit.2$fitted.values, German$Creditability)

#Get the predictions using the predict function
German_predict <- predict( fit.2,type='response')

qplot(German_predict)
```






